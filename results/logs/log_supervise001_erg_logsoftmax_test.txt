nohup: ignoring input
| Xavier Initialization
| Xavier Initialization
Training started
/SCRATCH/liudefen/PycharmProjects/gnn/GraphRL/gcn/models_gcn.py:85: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
epochs 0 loss 2.1808685951085325
epoch 0000 gcn2mind min_ratio 1.0806697108066972 max_ratio 1.136964980544747 av_ratio 1.107269047350243
epochs 1 loss 2.1511309892370756
epoch 0001 gcn2mind min_ratio 1.0818713450292399 max_ratio 1.1357927786499216 av_ratio 1.1047105528132817
epochs 2 loss 2.485093761278635
epoch 0002 gcn2mind min_ratio 1.0964581763376036 max_ratio 1.1357927786499216 av_ratio 1.109935370205787
epochs 3 loss 2.265668667896038
epoch 0003 gcn2mind min_ratio 1.0892053973013494 max_ratio 1.1311093871217999 av_ratio 1.1146816317713406
epochs 4 loss 2.2552018426790292
epoch 0004 gcn2mind min_ratio 1.090704647676162 max_ratio 1.1289592760180995 av_ratio 1.1150581446562011
epochs 5 loss 2.2057180889382417
epoch 0005 gcn2mind min_ratio 1.0721884498480243 max_ratio 1.130739299610895 av_ratio 1.1039266418108868
epochs 6 loss 2.292036358310228
epoch 0006 gcn2mind min_ratio 1.0895741556534508 max_ratio 1.1221789883268483 av_ratio 1.1095722046488372
epochs 7 loss 2.2728390954866464
epoch 0007 gcn2mind min_ratio 1.0862068965517242 max_ratio 1.1326530612244898 av_ratio 1.1133172910351072
epochs 8 loss 2.307332966519838
epoch 0008 gcn2mind min_ratio 1.0861280487804879 max_ratio 1.1350078492935636 av_ratio 1.1139420876591815
epochs 9 loss 2.6165125482215936
epoch 0009 gcn2mind min_ratio 1.0608308605341246 max_ratio 1.132295719844358 av_ratio 1.1013534012561825
epochs 10 loss 2.397039629562145
epoch 0010 gcn2mind min_ratio 1.074468085106383 max_ratio 1.1389324960753533 av_ratio 1.108420976788262
epochs 11 loss 2.2735832371249254
epoch 0011 gcn2mind min_ratio 1.0874439461883407 max_ratio 1.130739299610895 av_ratio 1.114276881828113
epochs 12 loss 2.0530964732601698
epoch 0012 gcn2mind min_ratio 1.0971810089020773 max_ratio 1.1326609775019394 av_ratio 1.114315908806556
epochs 13 loss 2.178379409058338
epoch 0013 gcn2mind min_ratio 1.0608365019011408 max_ratio 1.1289592760180995 av_ratio 1.1053918369113114
epochs 14 loss 2.2489379197790678
epoch 0014 gcn2mind min_ratio 1.095952023988006 max_ratio 1.129182879377432 av_ratio 1.1144274991756054
epochs 15 loss 2.1700434647932108
epoch 0015 gcn2mind min_ratio 1.0851688693098385 max_ratio 1.139643134212568 av_ratio 1.1166964421616639
epochs 16 loss 2.13688526306892
epoch 0016 gcn2mind min_ratio 1.0814977973568283 max_ratio 1.1297134238310709 av_ratio 1.1091530093890867
epochs 17 loss 2.2178114876582677
epoch 0017 gcn2mind min_ratio 1.0732436472346787 max_ratio 1.1244343891402715 av_ratio 1.1114949549025768
epochs 18 loss 1.1824001582839392
epoch 0018 gcn2mind min_ratio 0.9924471299093656 max_ratio 1.0259026687598116 av_ratio 1.007519678070804
epochs 19 loss 0.11542375851506748
epoch 0019 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.0243328100470959 av_ratio 1.0046869036573685
epochs 20 loss 0.08256208910679952
epoch 0020 gcn2mind min_ratio 1.0 max_ratio 1.0251177394034536 av_ratio 1.0068006877861557
epochs 21 loss 0.08334427761156338
epoch 0021 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0263752825923136 av_ratio 1.0078647920989876
epochs 22 loss 0.07333789409469826
epoch 0022 gcn2mind min_ratio 0.9970631424375918 max_ratio 1.0243328100470959 av_ratio 1.0048366340286303
epochs 23 loss 0.09363721986276019
epoch 0023 gcn2mind min_ratio 0.9977578475336323 max_ratio 1.0243328100470959 av_ratio 1.0042294845183348
epochs 24 loss 0.07288714848145172
epoch 0024 gcn2mind min_ratio 0.9786293294030951 max_ratio 1.0243328100470959 av_ratio 0.9993801981761001
epochs 25 loss 0.05849151279785669
epoch 0025 gcn2mind min_ratio 0.9911634756995582 max_ratio 1.013595166163142 av_ratio 1.0025090136037749
epochs 26 loss 0.08133841386253682
epoch 0026 gcn2mind min_ratio 0.9977578475336323 max_ratio 1.0243328100470959 av_ratio 1.0050842335015289
epochs 27 loss 0.07033558426697972
epoch 0027 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.0243328100470959 av_ratio 1.0030146176358925
epochs 28 loss 0.08613175733643263
epoch 0028 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.0256024096385543 av_ratio 1.0053049418543445
epochs 29 loss 0.0866235122353416
epoch 0029 gcn2mind min_ratio 1.0 max_ratio 1.0240496508921644 av_ratio 1.007056030382389
epochs 30 loss 0.07679127608613623
epoch 0030 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.020946470131885 av_ratio 1.0004851086245528
epochs 31 loss 0.09511005242813741
epoch 0031 gcn2mind min_ratio 0.9977578475336323 max_ratio 1.0068649885583525 av_ratio 1.0009928767643181
epochs 32 loss 0.08644235593099125
epoch 0032 gcn2mind min_ratio 1.0 max_ratio 1.0251177394034536 av_ratio 1.0077877966445572
epochs 33 loss 0.08099120248338743
epoch 0033 gcn2mind min_ratio 0.9977578475336323 max_ratio 1.0243328100470959 av_ratio 1.0046178128440946
epochs 34 loss 0.084972401141723
epoch 0034 gcn2mind min_ratio 0.989329268292683 max_ratio 1.0251177394034536 av_ratio 0.999529846053601
epochs 35 loss 0.0679803283822622
epoch 0035 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0127340823970037 av_ratio 1.0005503861416378
epochs 36 loss 0.07072704263859286
epoch 0036 gcn2mind min_ratio 0.9940074906367041 max_ratio 1.0243328100470959 av_ratio 1.005722674682819
epochs 37 loss 0.07271942764664274
epoch 0037 gcn2mind min_ratio 0.9955817378497791 max_ratio 1.0243328100470959 av_ratio 1.0048067698081482
epochs 38 loss 0.08028979067092656
epoch 0038 gcn2mind min_ratio 0.9970104633781763 max_ratio 1.0243328100470959 av_ratio 1.0055147244114715
epochs 39 loss 0.08707264190209152
epoch 0039 gcn2mind min_ratio 0.9924471299093656 max_ratio 1.0144376899696048 av_ratio 1.0012043685725218
epochs 40 loss 0.07299444465934801
epoch 0040 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.0243328100470959 av_ratio 1.0052268068377699
epochs 41 loss 0.0746822671862013
epoch 0041 gcn2mind min_ratio 0.9956140350877193 max_ratio 1.0251177394034536 av_ratio 1.00508478132083
epochs 42 loss 0.078963567529021
epoch 0042 gcn2mind min_ratio 1.0 max_ratio 1.0169491525423728 av_ratio 1.0029782588485205
epochs 43 loss 0.06544624079244965
epoch 0043 gcn2mind min_ratio 1.0 max_ratio 1.0251177394034536 av_ratio 1.0062293462798082
epochs 44 loss 0.0807510245755596
epoch 0044 gcn2mind min_ratio 0.9948830409356725 max_ratio 1.0243328100470959 av_ratio 1.0054775881392009
epochs 45 loss 0.07975194184145451
epoch 0045 gcn2mind min_ratio 1.0 max_ratio 1.0251177394034536 av_ratio 1.0053662445707392
epochs 46 loss 0.08578806243461301
epoch 0046 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.008544676955755
epochs 47 loss 0.07043970228001317
epoch 0047 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0047225971439242
epochs 48 loss 0.08060055272928501
epoch 0048 gcn2mind min_ratio 0.9911634756995582 max_ratio 1.0148367952522255 av_ratio 1.0009108295305569
epochs 49 loss 0.07166018901480609
epoch 0049 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0080435114418569
Training finished
Training time: 304.6500
Elimination time: 29.5400
Heuristic time: 2.4600
Dense 2 Sparce time: 10.9100
IO to cuda time: 5.3700
Model and Opt time: 76.4600
| Xavier Initialization
| Xavier Initialization
test stated
test finished
Test time: 24.5476
