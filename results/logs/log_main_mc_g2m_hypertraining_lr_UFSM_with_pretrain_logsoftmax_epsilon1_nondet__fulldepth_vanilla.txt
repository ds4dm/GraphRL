nohup: ignoring input
[[1 2 3]
 [4 5 6]]
| Xavier Initialization
| Xavier Initialization
Supervised Training started
heuristic: min_degree actor learning rate: 0.0001 epochs: 100 DataSet: UFSMDataset

Use Critic:
False
/local_workspace/liudefen/PycharmProjects/PycharmProjects/PycharmProjects/gnn/GraphRL/gcn/models_gcn.py:85: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
epochs 0 loss -465.3736877441406
epoch 0000 gcn2min_degree  train av_ratio 0.918450487796162  validation av_ratio 0.959252104012613
parameter name actor.gc1.weight parameter value tensor(1.00000e-04 *
       [[-7.0304]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor([ 1.3975], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor([[-1.2467]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor(1.00000e-04 *
       [ 2.2029], device='cuda:0')
epochs 1 loss -227.22735595703125
epochs 2 loss -419.8795166015625
epochs 3 loss -381.72457122802734
epochs 4 loss -524.7979888916016
epochs 5 loss -568.6089096069336
epochs 6 loss -335.8544616699219
epochs 7 loss -588.9829788208008
epochs 8 loss -332.22483825683594
epochs 9 loss -576.3117370605469
epochs 10 loss -473.1024932861328
epochs 11 loss -404.7659606933594
epochs 12 loss -290.5031280517578
epochs 13 loss -514.0108108520508
epochs 14 loss -442.64390563964844
epochs 15 loss -665.1593627929688
epochs 16 loss -564.3755645751953
epochs 17 loss -564.9389190673828
epochs 18 loss -395.0081481933594
epochs 19 loss -495.8714294433594
epochs 20 loss -243.526123046875
epochs 21 loss -357.5250244140625
epochs 22 loss -331.6625213623047
epochs 23 loss -469.2306671142578
epochs 24 loss -441.24607849121094
epochs 25 loss -287.24070739746094
epochs 26 loss -266.9297561645508
epochs 27 loss -346.8587188720703
epochs 28 loss -572.0116500854492
epochs 29 loss -517.6713104248047
epochs 30 loss -373.09971618652344
epochs 31 loss -685.1607551574707
epochs 32 loss -698.7578887939453
epochs 33 loss -394.72462463378906
epochs 34 loss -558.4593200683594
epochs 35 loss -591.3809585571289
epochs 36 loss -447.60662841796875
epochs 37 loss -568.1306838989258
epochs 38 loss -320.683349609375
epochs 39 loss -580.5634536743164
epochs 40 loss -589.2006072998047
epochs 41 loss -589.0485458374023
epochs 42 loss -476.0585479736328
epochs 43 loss -394.8392028808594
epochs 44 loss -395.78387451171875
epochs 45 loss -388.3583526611328
epochs 46 loss -462.40584564208984
epochs 47 loss -432.8162384033203
epochs 48 loss -410.17457580566406
epochs 49 loss -283.35459899902344
epochs 50 loss -334.13368225097656
epochs 51 loss -478.7861328125
epochs 52 loss -485.8585968017578
epochs 53 loss -504.66382598876953
epochs 54 loss -595.339599609375
epochs 55 loss -378.17115783691406
epochs 56 loss -406.0266571044922
epochs 57 loss -433.05787658691406
epochs 58 loss -340.2316436767578
epochs 59 loss -380.95372009277344
epochs 60 loss -404.4728546142578
epochs 61 loss -431.1647491455078
epochs 62 loss -529.2992706298828
epochs 63 loss -396.1947326660156
epochs 64 loss -435.788818359375
epochs 65 loss -450.5557556152344
epochs 66 loss -439.1177978515625
epochs 67 loss -470.61761474609375
epochs 68 loss -513.0463562011719
epochs 69 loss -506.12646484375
epochs 70 loss -350.03273010253906
epochs 71 loss -383.0613250732422
epochs 72 loss -422.8652114868164
epochs 73 loss -353.9748077392578
epochs 74 loss -597.5228576660156
epochs 75 loss -348.56068420410156
epochs 76 loss -300.31683349609375
epochs 77 loss -541.3602905273438
epochs 78 loss -506.4320068359375
epochs 79 loss -313.4795379638672
epochs 80 loss -458.53794860839844
epochs 81 loss -468.08221435546875
epochs 82 loss -446.6597900390625
epochs 83 loss -409.9333801269531
epochs 84 loss -501.7138900756836
epochs 85 loss -507.3106384277344
epochs 86 loss -621.9606628417969
epochs 87 loss -399.8235778808594
epochs 88 loss -532.4115219116211
epochs 89 loss -409.13551330566406
epochs 90 loss -482.47282791137695
epochs 91 loss -404.6095275878906
epochs 92 loss -508.9821243286133
epochs 93 loss -566.6877365112305
epochs 94 loss -574.4528503417969
epochs 95 loss -414.1075134277344
epochs 96 loss -497.8445281982422
epochs 97 loss -478.34718322753906
epochs 98 loss -416.3465881347656
epochs 99 loss -505.9736785888672
epochs 100 loss -422.3228225708008
Use Critic:
False
epochs 0 loss -465.3736877441406
epoch 0000 gcn2min_degree  train av_ratio 0.9637573825817943  validation av_ratio 0.9416663033526617
parameter name actor.gc1.weight parameter value tensor(1.00000e-04 *
       [[-7.0304]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor([ 1.3975], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor([[-1.2467]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor(1.00000e-04 *
       [ 2.2029], device='cuda:0')
epochs 1 loss -431.0108413696289
epochs 2 loss -514.1996917724609
epochs 3 loss -425.77439880371094
epochs 4 loss -441.9795684814453
epochs 5 loss -374.8946838378906
epochs 6 loss -610.8338623046875
epochs 7 loss -303.73423767089844
epochs 8 loss -146.42117309570312
epochs 9 loss -2.6711196899414062
epochs 10 loss 176.42167854309082
epochs 11 loss 400.7340278625488
epochs 12 loss 461.0448913574219
epochs 13 loss 599.1516418457031
epochs 14 loss 725.094386100769
epochs 15 loss 659.0576820373535
epochs 16 loss 891.0627536773682
epochs 17 loss 1054.1557922363281
epochs 18 loss 926.3733024597168
epochs 19 loss 883.179979801178
epochs 20 loss 952.2735729217529
epochs 21 loss 1187.6898651123047
epochs 22 loss 1004.4109878540039
epochs 23 loss 1256.4515628814697
epochs 24 loss 1249.4188995361328
epochs 25 loss 1176.1001358032227
epochs 26 loss 1185.7733726501465
epochs 27 loss 1297.737159729004
epochs 28 loss 1184.7516822814941
epochs 29 loss 1262.4359588623047
epochs 30 loss 1187.4465827941895
epochs 31 loss 1472.5774383544922
epochs 32 loss 1448.9037551879883
epochs 33 loss 1242.2433776855469
epochs 34 loss 1327.7734298706055
epochs 35 loss 1310.1703567504883
epochs 36 loss 1383.5779132843018
epochs 37 loss 1621.2935638427734
epochs 38 loss 1441.6126403808594
epochs 39 loss 1455.5994567871094
epochs 40 loss 1366.997413635254
epochs 41 loss 1719.9498901367188
epochs 42 loss 1286.999179840088
epochs 43 loss 1598.7686004638672
epochs 44 loss 1474.6584701538086
epochs 45 loss 1559.7826690673828
epochs 46 loss 1430.2052764892578
epochs 47 loss 1276.6898956298828
epochs 48 loss 1376.9762992858887
epochs 49 loss 1546.5826110839844
epochs 50 loss 1513.2799682617188
epochs 51 loss 1419.0447692871094
epochs 52 loss 1586.0156555175781
epochs 53 loss 1349.0324935913086
epochs 54 loss 1270.9241638183594
epochs 55 loss 1408.2117309570312
epochs 56 loss 1217.2108306884766
epochs 57 loss 1048.3265953063965
epochs 58 loss 1329.6574325561523
epochs 59 loss 1313.5870208740234
epochs 60 loss 1198.5581741333008
epochs 61 loss 1458.401912689209
epochs 62 loss 1276.1098823547363
epochs 63 loss 1432.9884719848633
epochs 64 loss 1435.4875793457031
epochs 65 loss 1322.5551147460938
epochs 66 loss 1125.8669185638428
epochs 67 loss 1027.094367980957
epochs 68 loss 1069.6178874969482
epochs 69 loss 1021.8224258422852
epochs 70 loss 1056.1837768554688
epochs 71 loss 986.5513591766357
epochs 72 loss 1031.7263989448547
epochs 73 loss 1055.3429718017578
epochs 74 loss 1149.95583152771
epochs 75 loss 1133.4295711517334
epochs 76 loss 906.6899604797363
epochs 77 loss 1020.7370262145996
epochs 78 loss 840.7195281982422
epochs 79 loss 1004.8235549926758
epochs 80 loss 1058.4686965942383
epochs 81 loss 883.016716003418
epochs 82 loss 926.8157806396484
epochs 83 loss 984.0132904052734
epochs 84 loss 574.3074741363525
epochs 85 loss 804.2775802612305
epochs 86 loss 1120.5281600952148
epochs 87 loss 918.2233276367188
epochs 88 loss 940.0144004821777
epochs 89 loss 1165.2909984588623
epochs 90 loss 976.9728050231934
epochs 91 loss 1056.2333698272705
epochs 92 loss 935.9938888549805
epochs 93 loss 880.8521041870117
epochs 94 loss 796.1488189697266
epochs 95 loss 950.5960597991943
epochs 96 loss 680.1785507202148
epochs 97 loss 591.7094211578369
epochs 98 loss 714.9174900054932
epochs 99 loss 631.6308584213257
epochs 100 loss 437.90832901000977
Use Critic:
False
epochs 0 loss -465.3736877441406
epoch 0000 gcn2min_degree  train av_ratio 0.9637573825817943  validation av_ratio 0.9856256274527699
parameter name actor.gc1.weight parameter value tensor(1.00000e-04 *
       [[-7.0304]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor([ 1.3975], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor([[-1.2467]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor(1.00000e-04 *
       [ 2.2029], device='cuda:0')
epochs 1 loss -826.4502868652344
epochs 2 loss -1392.9234924316406
epochs 3 loss -1667.4736938476562
epochs 4 loss -1627.4865417480469
epochs 5 loss -1406.9405822753906
epochs 6 loss -408.5899963378906
epochs 7 loss 109.61263465881348
epochs 8 loss 401.9671058654785
epochs 9 loss 560.5995941162109
epochs 10 loss 486.49626541137695
epochs 11 loss 635.2896251678467
epochs 12 loss 861.8221545219421
epochs 13 loss 784.8486294746399
epochs 14 loss 1061.4564838409424
epochs 15 loss 1001.727952003479
epochs 16 loss 1184.7895755767822
epochs 17 loss 1166.1129455566406
epochs 18 loss 1319.8654403686523
epochs 19 loss 1197.9468154907227
epochs 20 loss 1330.6551666259766
epochs 21 loss 1201.740966796875
epochs 22 loss 1541.4092636108398
epochs 23 loss 1397.0140686035156
epochs 24 loss 1521.3945541381836
epochs 25 loss 1390.569679260254
epochs 26 loss 1545.0030059814453
epochs 27 loss 1262.7223587036133
epochs 28 loss 1325.29736328125
epochs 29 loss 1480.252914428711
epochs 30 loss 1473.344108581543
epochs 31 loss 1559.4806823730469
epochs 32 loss 1521.766830444336
epochs 33 loss 1518.6742858886719
epochs 34 loss 1295.192512512207
epochs 35 loss 1188.1143741607666
epochs 36 loss 1195.056308746338
epochs 37 loss 1458.5952835083008
epochs 38 loss 1450.2279891967773
epochs 39 loss 1635.568000793457
epochs 40 loss 1316.8258209228516
epochs 41 loss 1396.096694946289
epochs 42 loss 1379.408576965332
epochs 43 loss 1450.835205078125
epochs 44 loss 1438.0808334350586
epochs 45 loss 1370.270004272461
epochs 46 loss 1597.9306259155273
epochs 47 loss 1434.088279724121
epochs 48 loss 1357.4798049926758
epochs 49 loss 1739.577049255371
epochs 50 loss 1641.3319625854492
epochs 51 loss 1632.5473937988281
epochs 52 loss 1627.2453002929688
epochs 53 loss 1601.3278274536133
epochs 54 loss 1475.0884475708008
epochs 55 loss 1576.6574592590332
epochs 56 loss 1799.6844635009766
epochs 57 loss 1676.868309020996
epochs 58 loss 1398.8851699829102
epochs 59 loss 1571.5746021270752
epochs 60 loss 1409.3630065917969
epochs 61 loss 1536.9629211425781
epochs 62 loss 1259.526035308838
epochs 63 loss 1447.9623260498047
epochs 64 loss 1398.6730041503906
epochs 65 loss 1182.1831398010254
epochs 66 loss 1224.8061218261719
epochs 67 loss 908.4958839416504
epochs 68 loss 1307.4744110107422
epochs 69 loss 1033.4556159973145
epochs 70 loss 1257.2295761108398
epochs 71 loss 1038.2082538604736
epochs 72 loss 939.3918952941895
epochs 73 loss 1097.979133605957
epochs 74 loss 962.964804649353
epochs 75 loss 1215.5984115600586
epochs 76 loss 1183.180591583252
epochs 77 loss 1289.0992164611816
epochs 78 loss 1222.2708282470703
epochs 79 loss 1107.0077056884766
epochs 80 loss 843.421422958374
epochs 81 loss 918.5677032470703
epochs 82 loss 919.4483184814453
epochs 83 loss 791.9990615844727
epochs 84 loss 633.2006721496582
epochs 85 loss 764.7052993774414
epochs 86 loss 782.2897706031799
epochs 87 loss 825.5194931030273
epochs 88 loss 921.144229888916
epochs 89 loss 1094.5211944580078
epochs 90 loss 653.9735069274902
epochs 91 loss 915.6386585235596
epochs 92 loss 755.1871433258057
epochs 93 loss 804.9374239444733
epochs 94 loss 746.2984848022461
epochs 95 loss 875.6007232666016
epochs 96 loss 665.9138133525848
epochs 97 loss 471.634033203125
epochs 98 loss 357.32129669189453
epochs 99 loss 366.54576301574707
epochs 100 loss 252.01885986328125
Use Critic:
False
epochs 0 loss -465.3736877441406
epoch 0000 gcn2min_degree  train av_ratio 0.9171394925596831  validation av_ratio 0.951854218539982
parameter name actor.gc1.weight parameter value tensor(1.00000e-04 *
       [[-7.0304]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor([ 1.3975], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor([[-1.2467]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor(1.00000e-04 *
       [ 2.2029], device='cuda:0')
epochs 1 loss -997.8731079101562
epochs 2 loss 92.53468322753906
epochs 3 loss 889.8813362121582
epochs 4 loss 1302.099220275879
epochs 5 loss 1782.344970703125
epochs 6 loss 1553.4492874145508
epochs 7 loss 1764.3161010742188
epochs 8 loss 1863.0355834960938
epochs 9 loss 1867.5930786132812
epochs 10 loss 1960.3843231201172
epochs 11 loss 1747.2991943359375
epochs 12 loss 1772.1479873657227
epochs 13 loss 1736.2521133422852
epochs 14 loss 1957.6332702636719
epochs 15 loss 1765.2483825683594
epochs 16 loss 1921.2569274902344
epochs 17 loss 1740.6838684082031
epochs 18 loss 1763.382827758789
epochs 19 loss 1974.4080047607422
epochs 20 loss 1995.9748840332031
epochs 21 loss 2364.244842529297
epochs 22 loss 2122.8373107910156
epochs 23 loss 1968.6877746582031
epochs 24 loss 2164.2215270996094
epochs 25 loss 2025.8765869140625
epochs 26 loss 2181.362045288086
epochs 27 loss 2346.6990356445312
epochs 28 loss 2237.383010864258
epochs 29 loss 2072.7125854492188
epochs 30 loss 2028.7249145507812
epochs 31 loss 2248.3692016601562
epochs 32 loss 2403.814483642578
epochs 33 loss 2242.2081604003906
epochs 34 loss 2211.3729858398438
epochs 35 loss 2200.6866455078125
epochs 36 loss 2414.248748779297
epochs 37 loss 2385.240234375
epochs 38 loss 2581.588134765625
epochs 39 loss 2242.7518310546875
epochs 40 loss 2356.9482421875
epochs 41 loss 2327.1078033447266
epochs 42 loss 2230.12890625
epochs 43 loss 1933.325698852539
epochs 44 loss 2066.3054809570312
epochs 45 loss 1903.9687042236328
epochs 46 loss 1965.1736297607422
epochs 47 loss 1997.8734130859375
epochs 48 loss 2106.0670013427734
epochs 49 loss 2217.1007690429688
epochs 50 loss 2254.3628845214844
epochs 51 loss 2369.3408203125
epochs 52 loss 2452.203582763672
epochs 53 loss 2358.5280151367188
epochs 54 loss 2115.803497314453
epochs 55 loss 1966.3478088378906
epochs 56 loss 1928.739486694336
epochs 57 loss 2045.0703430175781
epochs 58 loss 1977.4034881591797
epochs 59 loss 1826.9912414550781
epochs 60 loss 1786.4776153564453
epochs 61 loss 1836.4316864013672
epochs 62 loss 2084.82861328125
epochs 63 loss 1863.455078125
epochs 64 loss 1873.6383819580078
epochs 65 loss 1721.5122833251953
epochs 66 loss 1720.4649124145508
epochs 67 loss 1509.1332931518555
epochs 68 loss 1550.2898712158203
epochs 69 loss 1625.3952026367188
epochs 70 loss 1913.8721313476562
epochs 71 loss 2099.2034606933594
epochs 72 loss 2088.1901092529297
epochs 73 loss 2233.5540466308594
epochs 74 loss 2193.7228393554688
epochs 75 loss 2220.661651611328
epochs 76 loss 2326.073028564453
epochs 77 loss 2141.672607421875
epochs 78 loss 2391.345962524414
epochs 79 loss 2254.7398834228516
epochs 80 loss 2161.948944091797
epochs 81 loss 2157.987991333008
epochs 82 loss 2500.141326904297
epochs 83 loss 2531.0385131835938
epochs 84 loss 2314.6444396972656
epochs 85 loss 2310.4923248291016
epochs 86 loss 2290.496047973633
epochs 87 loss 2530.5140838623047
epochs 88 loss 2274.1578674316406
epochs 89 loss 2608.839385986328
epochs 90 loss 2408.198486328125
epochs 91 loss 2275.3883361816406
epochs 92 loss 2359.285675048828
epochs 93 loss 2489.7866973876953
epochs 94 loss 2452.804931640625
epochs 95 loss 2419.0748291015625
epochs 96 loss 2304.020782470703
epochs 97 loss 2553.37841796875
epochs 98 loss 2784.892547607422
epochs 99 loss 2586.023162841797
epochs 100 loss 2586.167938232422
Use Critic:
False
epochs 0 loss -465.3736877441406
epoch 0000 gcn2min_degree  train av_ratio 0.9877022404980593  validation av_ratio 0.9905526255446
parameter name actor.gc1.weight parameter value tensor(1.00000e-04 *
       [[-7.0304]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor([ 1.3975], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor([[-1.2467]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor(1.00000e-04 *
       [ 2.2029], device='cuda:0')
epochs 1 loss -1700.6019897460938
epochs 2 loss -2620.8419799804688
epochs 3 loss -3058.117919921875
epochs 4 loss -2822.8829345703125
epochs 5 loss -2316.2205200195312
