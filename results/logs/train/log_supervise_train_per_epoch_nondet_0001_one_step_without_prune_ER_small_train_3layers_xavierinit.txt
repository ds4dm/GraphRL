nohup: ignoring input
cuda available: True 
cuda available: True 
cuda available: True 
cuda available: True 
model initialized
training func is running after this line
Supervised Training started
heuristic: one_step_greedy learning rate: 0.0001 epochs: 21 DataSet: ErgDataset

/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/gcn/models_gcn.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
epochs 0 loss 0.005040451331875746 one_step_greedyperformance 12639.035 gcn_performance 15172.145 one_step_greedyperformance 12445.19 gcn_performance 15989.085
epochs 1 loss 0.0022991391239909754 one_step_greedyperformance 12639.035 gcn_performance 14421.57 one_step_greedyperformance 12445.19 gcn_performance 12716.315
epochs 2 loss 0.0018752415570587667 one_step_greedyperformance 12639.035 gcn_performance 12907.17 one_step_greedyperformance 12445.19 gcn_performance 12607.08
epochs 3 loss 0.001727205069742998 one_step_greedyperformance 12639.035 gcn_performance 12887.225 one_step_greedyperformance 12445.19 gcn_performance 12589.605
epochs 4 loss 0.0017202134601407263 one_step_greedyperformance 12639.035 gcn_performance 12912.445 one_step_greedyperformance 12445.19 gcn_performance 12616.475
epochs 5 loss 0.0017141293341867289 one_step_greedyperformance 12639.035 gcn_performance 12932.81 one_step_greedyperformance 12445.19 gcn_performance 13486.765
epochs 6 loss 0.001747276681400654 one_step_greedyperformance 12639.035 gcn_performance 12927.595 one_step_greedyperformance 12445.19 gcn_performance 12570.5
epochs 7 loss 0.0017136323156884137 one_step_greedyperformance 12639.035 gcn_performance 12918.7 one_step_greedyperformance 12445.19 gcn_performance 12556.085
epochs 8 loss 0.0017317812818578998 one_step_greedyperformance 12639.035 gcn_performance 12884.445 one_step_greedyperformance 12445.19 gcn_performance 12579.635
epochs 9 loss 0.0017173359259632607 one_step_greedyperformance 12639.035 gcn_performance 12896.83 one_step_greedyperformance 12445.19 gcn_performance 13014.485
epochs 10 loss 0.0017286042431894273 one_step_greedyperformance 12639.035 gcn_performance 12904.255 one_step_greedyperformance 12445.19 gcn_performance 12657.645
epochs 11 loss 0.0017059529532980448 one_step_greedyperformance 12639.035 gcn_performance 12899.235 one_step_greedyperformance 12445.19 gcn_performance 12566.815
epochs 12 loss 0.0017044475943187346 one_step_greedyperformance 12639.035 gcn_performance 12887.515 one_step_greedyperformance 12445.19 gcn_performance 12936.055
epochs 13 loss 0.001737471981796528 one_step_greedyperformance 12639.035 gcn_performance 12970.485 one_step_greedyperformance 12445.19 gcn_performance 12549.785
epochs 14 loss 0.0017600827429944627 one_step_greedyperformance 12639.035 gcn_performance 12888.525 one_step_greedyperformance 12445.19 gcn_performance 13168.765
epochs 15 loss 0.0017188858502221243 one_step_greedyperformance 12639.035 gcn_performance 12911.36 one_step_greedyperformance 12445.19 gcn_performance 12889.985
epochs 16 loss 0.0017201280827792971 one_step_greedyperformance 12639.035 gcn_performance 12924.315 one_step_greedyperformance 12445.19 gcn_performance 12566.245
epochs 17 loss 0.0017568449207768099 one_step_greedyperformance 12639.035 gcn_performance 12922.25 one_step_greedyperformance 12445.19 gcn_performance 12748.825
epochs 18 loss 0.0017191484521427353 one_step_greedyperformance 12639.035 gcn_performance 12873.975 one_step_greedyperformance 12445.19 gcn_performance 12857.395
epochs 19 loss 0.0017408057532544126 one_step_greedyperformance 12639.035 gcn_performance 12873.645 one_step_greedyperformance 12445.19 gcn_performance 12558.64
epochs 20 loss 0.001705946612686758 one_step_greedyperformance 12639.035 gcn_performance 12903.955 one_step_greedyperformance 12445.19 gcn_performance 12789.075
Finished
Training time: 237341.6500
Elimination time: 1.7800
Heuristicone_step_greedy time: 209933.4500
Dense 2 Sparce time: 551.4100
IO to cuda time: 240.9100
Model and Opt time: 1902.4300
