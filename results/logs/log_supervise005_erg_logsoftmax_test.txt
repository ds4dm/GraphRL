nohup: ignoring input
| Xavier Initialization
| Xavier Initialization
Training started
/SCRATCH/liudefen/PycharmProjects/gnn/GraphRL/gcn/models_gcn.py:85: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
epochs 0 loss 2.1628475562169607
epoch 0000 gcn2mind min_ratio 1.0806697108066972 max_ratio 1.136964980544747 av_ratio 1.107269047350243
epochs 1 loss 2.1511309892370756
epoch 0001 gcn2mind min_ratio 1.0818713450292399 max_ratio 1.1357927786499216 av_ratio 1.1047105528132817
epochs 2 loss 2.485093761278635
epoch 0002 gcn2mind min_ratio 1.0964581763376036 max_ratio 1.1357927786499216 av_ratio 1.109935370205787
epochs 3 loss 2.265668667896038
epoch 0003 gcn2mind min_ratio 1.0892053973013494 max_ratio 1.1311093871217999 av_ratio 1.1146816317713406
epochs 4 loss 2.2552018426790292
epoch 0004 gcn2mind min_ratio 1.090704647676162 max_ratio 1.1289592760180995 av_ratio 1.1150581446562011
epochs 5 loss 2.2057180889382417
epoch 0005 gcn2mind min_ratio 1.0721884498480243 max_ratio 1.130739299610895 av_ratio 1.1039266418108868
epochs 6 loss 2.292036358310228
epoch 0006 gcn2mind min_ratio 1.0895741556534508 max_ratio 1.1221789883268483 av_ratio 1.1095722046488372
epochs 7 loss 2.2728390954866464
epoch 0007 gcn2mind min_ratio 1.0862068965517242 max_ratio 1.1326530612244898 av_ratio 1.1133172910351072
epochs 8 loss 2.307332966519838
epoch 0008 gcn2mind min_ratio 1.0861280487804879 max_ratio 1.1350078492935636 av_ratio 1.1139420876591815
epochs 9 loss 2.6165125482215936
epoch 0009 gcn2mind min_ratio 1.0608308605341246 max_ratio 1.132295719844358 av_ratio 1.1013534012561825
epochs 10 loss 2.397039629562145
epoch 0010 gcn2mind min_ratio 1.074468085106383 max_ratio 1.1389324960753533 av_ratio 1.108420976788262
epochs 11 loss 2.2735832371249254
epoch 0011 gcn2mind min_ratio 1.0874439461883407 max_ratio 1.130739299610895 av_ratio 1.114276881828113
epochs 12 loss 2.0530964732601698
epoch 0012 gcn2mind min_ratio 1.0971810089020773 max_ratio 1.1326609775019394 av_ratio 1.114315908806556
epochs 13 loss 2.178379409058338
epoch 0013 gcn2mind min_ratio 1.0608365019011408 max_ratio 1.1289592760180995 av_ratio 1.1053918369113114
epochs 14 loss 2.2489379197790678
epoch 0014 gcn2mind min_ratio 1.095952023988006 max_ratio 1.129182879377432 av_ratio 1.1144274991756054
epochs 15 loss 1.460464751365814
epoch 0015 gcn2mind min_ratio 0.9948604992657856 max_ratio 1.0243328100470959 av_ratio 1.004476490983833
epochs 16 loss 0.08730626071317893
epoch 0016 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.0243328100470959 av_ratio 1.0021485425000198
epochs 17 loss 0.09148604072210453
epoch 0017 gcn2mind min_ratio 0.9904552129221733 max_ratio 1.0243328100470959 av_ratio 1.0043694080264352
epochs 18 loss 0.0767411459798355
epoch 0018 gcn2mind min_ratio 0.9992469879518072 max_ratio 1.0243328100470959 av_ratio 1.0058951844196344
epochs 19 loss 0.08590408574244712
epoch 0019 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0071096417067724
epochs 20 loss 0.0814399815592699
epoch 0020 gcn2mind min_ratio 0.9956140350877193 max_ratio 1.0243328100470959 av_ratio 1.0055735485243127
epochs 21 loss 0.0982447599391536
epoch 0021 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.005770355442692
epochs 22 loss 0.08713321017485676
epoch 0022 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0078689236724485
epochs 23 loss 0.11994360699303108
epoch 0023 gcn2mind min_ratio 0.9955784819454679 max_ratio 1.0243328100470959 av_ratio 1.0032784176587217
epochs 24 loss 0.08093172221827238
epoch 0024 gcn2mind min_ratio 0.9947565543071161 max_ratio 1.0243328100470959 av_ratio 1.0046978119048477
epochs 25 loss 0.06240084791119216
epoch 0025 gcn2mind min_ratio 1.0 max_ratio 1.0224719101123596 av_ratio 1.0072545765733527
epochs 26 loss 0.0899178508734968
epoch 0026 gcn2mind min_ratio 0.9970631424375918 max_ratio 1.0243328100470959 av_ratio 1.0044785856042808
epochs 27 loss 0.07822983638574321
epoch 0027 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0251177394034536 av_ratio 1.0050372261735032
epochs 28 loss 0.11402744704402057
epoch 0028 gcn2mind min_ratio 1.0 max_ratio 1.0256024096385543 av_ratio 1.007698337132744
epochs 29 loss 0.09584162465231394
epoch 0029 gcn2mind min_ratio 1.0 max_ratio 1.0240496508921644 av_ratio 1.0050994155923232
epochs 30 loss 0.09004483840781496
epoch 0030 gcn2mind min_ratio 0.9904552129221733 max_ratio 1.0243328100470959 av_ratio 1.0016361302611652
epochs 31 loss 0.11241256952987921
epoch 0031 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.013677811550152 av_ratio 1.0007522393868045
epochs 32 loss 0.10765950761662602
epoch 0032 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0093180515542763
epochs 33 loss 0.08483380435371046
epoch 0033 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0243328100470959 av_ratio 1.0048886558695498
epochs 34 loss 0.09727404571457932
epoch 0034 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.0243328100470959 av_ratio 1.001295253504677
epochs 35 loss 0.07119398115042497
epoch 0035 gcn2mind min_ratio 1.0 max_ratio 1.0188394875659381 av_ratio 1.0057034651313765
epochs 36 loss 0.07518186552402906
epoch 0036 gcn2mind min_ratio 0.9992469879518072 max_ratio 1.0243328100470959 av_ratio 1.0045586726950746
epochs 37 loss 0.08277341715518372
epoch 0037 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0243328100470959 av_ratio 1.0037754932801755
epochs 38 loss 0.09533411931935198
epoch 0038 gcn2mind min_ratio 0.9948453608247423 max_ratio 1.0243328100470959 av_ratio 1.0037543073136
epochs 39 loss 0.09200039835210472
epoch 0039 gcn2mind min_ratio 0.9947565543071161 max_ratio 1.0240496508921644 av_ratio 1.0033643000451506
epochs 40 loss 0.08106319348178292
epoch 0040 gcn2mind min_ratio 1.0 max_ratio 1.0256024096385543 av_ratio 1.0056793236935024
epochs 41 loss 0.0799738722485488
epoch 0041 gcn2mind min_ratio 1.0 max_ratio 1.0251177394034536 av_ratio 1.0081601764872195
epochs 42 loss 0.09486892439604588
epoch 0042 gcn2mind min_ratio 1.0 max_ratio 1.0240496508921644 av_ratio 1.0051678157086523
epochs 43 loss 0.0630673146187486
epoch 0043 gcn2mind min_ratio 1.0 max_ratio 1.0251177394034536 av_ratio 1.0069420491524643
epochs 44 loss 0.08063531805290403
epoch 0044 gcn2mind min_ratio 0.989329268292683 max_ratio 1.0243328100470959 av_ratio 1.000631983958137
epochs 45 loss 0.08536727356090879
epoch 0045 gcn2mind min_ratio 0.9947565543071161 max_ratio 1.0243328100470959 av_ratio 1.0053873812898435
epochs 46 loss 0.09232690521341169
epoch 0046 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.004314008966714
epochs 47 loss 0.08151189728890351
epoch 0047 gcn2mind min_ratio 1.0 max_ratio 1.0263752825923136 av_ratio 1.0078093815241274
epochs 48 loss 0.08319491397792067
epoch 0048 gcn2mind min_ratio 0.9926578560939795 max_ratio 1.0240496508921644 av_ratio 1.0036096654286928
epochs 49 loss 0.0752975178736568
epoch 0049 gcn2mind min_ratio 0.9926578560939795 max_ratio 1.0243328100470959 av_ratio 1.0032322283428172
Training finished
Training time: 310.5400
Elimination time: 29.8700
Heuristic time: 2.8200
Dense 2 Sparce time: 11.2500
IO to cuda time: 5.6800
Model and Opt time: 73.2200
| Xavier Initialization
| Xavier Initialization
test stated
test finished
Test time: 25.1217
