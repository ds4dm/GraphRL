nohup: ignoring input
| Xavier Initialization
| Xavier Initialization
Training started
/SCRATCH/liudefen/PycharmProjects/gnn/GraphRL/gcn/models_gcn.py:85: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
epochs 0 loss 2.1593581401243265
epoch 0000 gcn2mind min_ratio 1.0806697108066972 max_ratio 1.136964980544747 av_ratio 1.107269047350243
epochs 1 loss 2.1511309892370756
epoch 0001 gcn2mind min_ratio 1.0818713450292399 max_ratio 1.1357927786499216 av_ratio 1.1047105528132817
epochs 2 loss 2.485093761278635
epoch 0002 gcn2mind min_ratio 1.0964581763376036 max_ratio 1.1357927786499216 av_ratio 1.109935370205787
epochs 3 loss 2.265668667896038
epoch 0003 gcn2mind min_ratio 1.0892053973013494 max_ratio 1.1311093871217999 av_ratio 1.1146816317713406
epochs 4 loss 2.2552018426790292
epoch 0004 gcn2mind min_ratio 1.090704647676162 max_ratio 1.1289592760180995 av_ratio 1.1150581446562011
epochs 5 loss 2.2057180889382417
epoch 0005 gcn2mind min_ratio 1.0721884498480243 max_ratio 1.130739299610895 av_ratio 1.1039266418108868
epochs 6 loss 2.292036358310228
epoch 0006 gcn2mind min_ratio 1.0895741556534508 max_ratio 1.1221789883268483 av_ratio 1.1095722046488372
epochs 7 loss 2.2728390954866464
epoch 0007 gcn2mind min_ratio 1.0862068965517242 max_ratio 1.1326530612244898 av_ratio 1.1133172910351072
epochs 8 loss 2.307332966519838
epoch 0008 gcn2mind min_ratio 1.0861280487804879 max_ratio 1.1350078492935636 av_ratio 1.1139420876591815
epochs 9 loss 2.6165125482215936
epoch 0009 gcn2mind min_ratio 1.0608308605341246 max_ratio 1.132295719844358 av_ratio 1.1013534012561825
epochs 10 loss 2.397039629562145
epoch 0010 gcn2mind min_ratio 1.074468085106383 max_ratio 1.1389324960753533 av_ratio 1.108420976788262
epochs 11 loss 0.4053588686504681
epoch 0011 gcn2mind min_ratio 0.989329268292683 max_ratio 1.0076103500761036 av_ratio 0.9993950081746963
epochs 12 loss 0.10237403200993889
epoch 0012 gcn2mind min_ratio 0.9985358711566618 max_ratio 1.0243328100470959 av_ratio 1.0064899088552834
epochs 13 loss 0.10806010533470634
epoch 0013 gcn2mind min_ratio 0.9955817378497791 max_ratio 1.0169491525423728 av_ratio 1.0029248215620115
epochs 14 loss 0.09548069538554849
epoch 0014 gcn2mind min_ratio 0.9926578560939795 max_ratio 1.0251177394034536 av_ratio 1.0058926763472922
epochs 15 loss 0.08850028771135987
epoch 0015 gcn2mind min_ratio 0.9926578560939795 max_ratio 1.0243328100470959 av_ratio 1.0041808118853555
epochs 16 loss 0.1150843686427172
epoch 0016 gcn2mind min_ratio 0.9861111111111112 max_ratio 1.0107858243451464 av_ratio 0.999889471823985
epochs 17 loss 0.14872693880880616
epoch 0017 gcn2mind min_ratio 0.9992469879518072 max_ratio 1.0243328100470959 av_ratio 1.0055370806944381
epochs 18 loss 0.09830412153202062
epoch 0018 gcn2mind min_ratio 0.9771723122238586 max_ratio 1.0243328100470959 av_ratio 1.0024749678080982
epochs 19 loss 0.10606910302687433
epoch 0019 gcn2mind min_ratio 0.9970104633781763 max_ratio 1.0243328100470959 av_ratio 1.0058122009171373
epochs 20 loss 0.08576505610233287
epoch 0020 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0078117556908068
epochs 21 loss 0.13457802779958206
epoch 0021 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.006492999960304
epochs 22 loss 0.10772318104401357
epoch 0022 gcn2mind min_ratio 1.0 max_ratio 1.0353915662650603 av_ratio 1.0138125637276145
epochs 23 loss 0.15814378249433458
epoch 0023 gcn2mind min_ratio 0.996186117467582 max_ratio 1.0251177394034536 av_ratio 1.0060355214070063
epochs 24 loss 0.09753781287615038
epoch 0024 gcn2mind min_ratio 0.9947565543071161 max_ratio 1.0243328100470959 av_ratio 1.004851866639317
epochs 25 loss 0.0710576789248405
epoch 0025 gcn2mind min_ratio 1.0 max_ratio 1.0224719101123596 av_ratio 1.0083926645854924
epochs 26 loss 0.0924950167151688
epoch 0026 gcn2mind min_ratio 0.9865067466266867 max_ratio 1.0259026687598116 av_ratio 1.0076610727973592
epochs 27 loss 0.09974648669854069
epoch 0027 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0251177394034536 av_ratio 1.0050372261735032
epochs 28 loss 0.13907534169311653
epoch 0028 gcn2mind min_ratio 1.0 max_ratio 1.0256024096385543 av_ratio 1.007698337132744
epochs 29 loss 0.11267033388878422
epoch 0029 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0073858537189124
epochs 30 loss 0.09580330504213741
epoch 0030 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0243328100470959 av_ratio 1.0035966858021135
epochs 31 loss 0.12112961380684473
epoch 0031 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.013677811550152 av_ratio 1.0007522393868045
epochs 32 loss 0.12815843071413768
epoch 0032 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0093180515542763
epochs 33 loss 0.11201948126560479
epoch 0033 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0243328100470959 av_ratio 1.0045949701133092
epochs 34 loss 0.11552702379173851
epoch 0034 gcn2mind min_ratio 0.9853801169590644 max_ratio 1.0243328100470959 av_ratio 1.001295253504677
epochs 35 loss 0.08247825170075274
epoch 0035 gcn2mind min_ratio 1.0 max_ratio 1.0188394875659381 av_ratio 1.0057034651313765
epochs 36 loss 0.08908049597379408
epoch 0036 gcn2mind min_ratio 0.9992469879518072 max_ratio 1.0243328100470959 av_ratio 1.0045586726950746
epochs 37 loss 0.08258343609879848
epoch 0037 gcn2mind min_ratio 0.9897209985315712 max_ratio 1.0243328100470959 av_ratio 1.0037754932801755
epochs 38 loss 0.11991296475232405
epoch 0038 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.005440092666745
epochs 39 loss 0.10682950560087079
epoch 0039 gcn2mind min_ratio 0.9947565543071161 max_ratio 1.0243328100470959 av_ratio 1.0057975810498603
epochs 40 loss 0.09165972166008984
epoch 0040 gcn2mind min_ratio 1.0 max_ratio 1.0256024096385543 av_ratio 1.005603278066126
epochs 41 loss 0.11550444350441635
epoch 0041 gcn2mind min_ratio 1.0 max_ratio 1.0251177394034536 av_ratio 1.0081601764872195
epochs 42 loss 0.13982887081234985
epoch 0042 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.007601096713362
epochs 43 loss 0.06837197618785096
epoch 0043 gcn2mind min_ratio 0.9948453608247423 max_ratio 1.0266875981161696 av_ratio 1.0081559909880418
epochs 44 loss 0.09120097799173088
epoch 0044 gcn2mind min_ratio 0.989329268292683 max_ratio 1.0243328100470959 av_ratio 1.001087219162993
epochs 45 loss 0.0857211334342809
epoch 0045 gcn2mind min_ratio 0.9947565543071161 max_ratio 1.0243328100470959 av_ratio 1.0053873812898435
epochs 46 loss 0.09696734242225569
epoch 0046 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0061342188402653
epochs 47 loss 0.10577227613733786
epoch 0047 gcn2mind min_ratio 1.0 max_ratio 1.0263752825923136 av_ratio 1.0078093815241274
epochs 48 loss 0.12367127195967864
epoch 0048 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0083563688664592
epochs 49 loss 0.08862436331685686
epoch 0049 gcn2mind min_ratio 1.0 max_ratio 1.0243328100470959 av_ratio 1.0084761218158247
Training finished
Training time: 295.7500
Elimination time: 29.0200
Heuristic time: 2.6400
Dense 2 Sparce time: 10.5300
IO to cuda time: 5.1700
Model and Opt time: 70.0200
| Xavier Initialization
| Xavier Initialization
test stated
test finished
Test time: 24.5536
