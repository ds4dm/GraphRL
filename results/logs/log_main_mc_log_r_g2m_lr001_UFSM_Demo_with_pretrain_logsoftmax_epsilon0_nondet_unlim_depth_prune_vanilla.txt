nohup: ignoring input
[[1 2 3]
 [4 5 6]]
| Xavier Initialization
| Xavier Initialization
Use Critic:
False
/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/gcn/models_gcn.py:85: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
epochs 0 loss 3155.9132385253906
parameter name actor.gc1.weight parameter value tensor(1.00000e-04 *
       [[-7.0304]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor([ 1.3975], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor([[-1.2467]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor(1.00000e-04 *
       [ 2.2029], device='cuda:0')
epochs 2 loss 2799.268341064453
epochs 3 loss 2880.1332092285156
epochs 4 loss 2607.687255859375
epochs 5 loss 2495.904296875
epochs 6 loss 2728.8068237304688
epochs 7 loss 2464.0185546875
epochs 8 loss 2337.196044921875
epochs 9 loss 2082.0835571289062
epochs 10 loss 2361.463592529297
epochs 11 loss 2149.2579040527344
epochs 12 loss 2104.921875
epochs 13 loss 1928.4152526855469
epochs 14 loss 2256.976776123047
epochs 15 loss 2300.888397216797
epochs 16 loss 1898.9753112792969
epochs 17 loss 1934.4109191894531
epochs 18 loss 2255.767120361328
epochs 19 loss 2316.5828857421875
epochs 20 loss 1786.9505004882812
epochs 21 loss 1942.5328063964844
epochs 22 loss 2204.569534301758
epochs 23 loss 1667.8764953613281
epochs 24 loss 2073.9192810058594
epochs 25 loss 2766.7219848632812
epochs 26 loss 2717.1629333496094
epochs 27 loss 2836.2315979003906
epochs 28 loss 2840.4120483398438
epochs 29 loss 2807.3516540527344
epochs 30 loss 2719.08642578125
epochs 31 loss 3041.7962036132812
epochs 32 loss 2954.528350830078
epochs 33 loss 2920.9810791015625
epochs 34 loss 3133.9634399414062
epochs 35 loss 3319.8200073242188
epochs 36 loss 3037.3381958007812
epochs 37 loss 3013.0339965820312
epochs 38 loss 3203.500732421875
epochs 39 loss 3048.551025390625
epochs 40 loss 2779.759307861328
epochs 41 loss 3227.0548706054688
epochs 42 loss 2948.1905212402344
epochs 43 loss 2942.1474609375
epochs 44 loss 2916.288330078125
epochs 45 loss 3188.5444946289062
epochs 46 loss 3204.1580200195312
epochs 47 loss 2698.298309326172
epochs 48 loss 3052.8363647460938
epochs 49 loss 3056.379638671875
epochs 50 loss 3103.7028198242188
epochs 51 loss 3047.7671508789062
epochs 52 loss 3175.8554077148438
epochs 53 loss 3184.4104919433594
epochs 54 loss 2952.6441040039062
epochs 55 loss 3128.0894775390625
epochs 56 loss 2885.3722534179688
epochs 57 loss 3263.8710327148438
epochs 58 loss 3031.9946899414062
epochs 59 loss 3046.3599853515625
epochs 60 loss 2804.242462158203
epochs 61 loss 3163.7488403320312
epochs 62 loss 3311.7992553710938
epochs 63 loss 3045.5349731445312
epochs 64 loss 3185.521728515625
epochs 65 loss 3044.7188415527344
epochs 66 loss 2986.3681640625
epochs 67 loss 3193.4675903320312
epochs 68 loss 2932.7380981445312
epochs 69 loss 2797.7428588867188
epochs 70 loss 3139.3952026367188
epochs 71 loss 3025.8817749023438
epochs 72 loss 3000.932373046875
epochs 73 loss 3069.5695190429688
epochs 74 loss 2912.0335083007812
epochs 75 loss 2944.9714965820312
epochs 76 loss 3004.6044921875
epochs 77 loss 3084.686767578125
epochs 78 loss 3072.4514770507812
epochs 79 loss 2921.3265075683594
epochs 80 loss 3040.774658203125
epochs 81 loss 2974.9312744140625
epochs 82 loss 2841.696502685547
epochs 83 loss 3071.6289672851562
epochs 84 loss 2976.5853271484375
epochs 85 loss 2965.852996826172
epochs 86 loss 3041.705352783203
epochs 87 loss 3066.3023681640625
epochs 88 loss 3015.7571411132812
epochs 89 loss 2990.5396728515625
epochs 90 loss 2802.654052734375
epochs 91 loss 3194.6537475585938
epochs 92 loss 3034.5983276367188
epochs 93 loss 3216.0803833007812
epochs 94 loss 2865.4234008789062
epochs 95 loss 2855.8766479492188
epochs 96 loss 2966.065216064453
epochs 97 loss 2753.8983154296875
epochs 98 loss 2902.7542419433594
epochs 99 loss 2939.2183532714844
epochs 100 loss 3235.9780883789062
epochs 101 loss 3063.8914489746094
epochs 102 loss 3037.706756591797
epochs 103 loss 2745.1267700195312
epochs 104 loss 2707.2454223632812
epochs 105 loss 3118.280975341797
epochs 106 loss 3116.1134643554688
epochs 107 loss 3027.9609985351562
epochs 108 loss 2893.1729736328125
epochs 109 loss 2945.2776489257812
epochs 110 loss 3043.93798828125
epochs 111 loss 3116.953857421875
epochs 112 loss 3276.404052734375
epochs 113 loss 2993.087860107422
epochs 114 loss 2758.0968322753906
epochs 115 loss 3060.1316833496094
epochs 116 loss 3272.4700317382812
epochs 117 loss 3096.2244262695312
epochs 118 loss 3133.0031127929688
epochs 119 loss 2844.5047912597656
epochs 120 loss 3007.5015258789062
epochs 121 loss 3091.0084838867188
epochs 122 loss 3095.82763671875
epochs 123 loss 3213.1015014648438
epochs 124 loss 3217.1561279296875
epochs 125 loss 3015.2392578125
epochs 126 loss 3043.8130493164062
epochs 127 loss 2834.5916748046875
epochs 128 loss 2998.6756591796875
epochs 129 loss 3355.3095092773438
epochs 130 loss 3404.6636352539062
epochs 131 loss 3256.6952514648438
epochs 132 loss 3290.2022705078125
epochs 133 loss 3304.6822509765625
epochs 134 loss 3456.3040771484375
epochs 135 loss 3219.45458984375
epochs 136 loss 3528.1943359375
epochs 137 loss 3370.2637329101562
epochs 138 loss 3354.0690307617188
epochs 139 loss 3405.5753784179688
epochs 140 loss 3168.6201782226562
epochs 141 loss 3728.8860473632812
epochs 142 loss 3459.1824340820312
epochs 143 loss 3581.5059204101562
epochs 144 loss 3141.9560546875
epochs 145 loss 3715.7924194335938
epochs 146 loss 3436.7884521484375
epochs 147 loss 3621.0731201171875
epochs 148 loss 3406.6971435546875
epochs 149 loss 3565.3456420898438
epochs 150 loss 3518.8441162109375
epochs 151 loss 3304.2667846679688
epochs 152 loss 3386.68310546875
epochs 153 loss 3388.2772216796875
epochs 154 loss 3405.3358764648438
epochs 155 loss 3215.4296875
epochs 156 loss 3257.2206420898438
epochs 157 loss 3372.6260986328125
epochs 158 loss 3380.6465454101562
epochs 159 loss 3331.5560913085938
epochs 160 loss 3551.9303588867188
epochs 161 loss 3477.8229370117188
epochs 162 loss 3337.977783203125
epochs 163 loss 3578.5735473632812
epochs 164 loss 3502.4644775390625
epochs 165 loss 3376.039581298828
epochs 166 loss 3587.99267578125
epochs 167 loss 3570.1387939453125
epochs 168 loss 3512.2056274414062
epochs 169 loss 3706.5372314453125
epochs 170 loss 3491.539794921875
epochs 171 loss 3525.8153076171875
epochs 172 loss 3515.0045776367188
epochs 173 loss 3615.5302734375
epochs 174 loss 3710.9744262695312
epochs 175 loss 3523.2001342773438
epochs 176 loss 3331.5069580078125
epochs 177 loss 3435.4180908203125
epochs 178 loss 3313.408935546875
epochs 179 loss 3522.0482788085938
epochs 180 loss 3418.2940063476562
epochs 181 loss 3499.1447143554688
epochs 182 loss 3384.4159545898438
epochs 183 loss 3417.4674072265625
epochs 184 loss 3455.517578125
epochs 185 loss 3359.5947875976562
epochs 186 loss 3607.534912109375
epochs 187 loss 3727.5100708007812
epochs 188 loss 3609.9229125976562
epochs 189 loss 3446.8936767578125
epochs 190 loss 3363.3568725585938
epochs 191 loss 3569.5089721679688
epochs 192 loss 3513.2194213867188
epochs 193 loss 3424.4190063476562
epochs 194 loss 3604.5899047851562
epochs 195 loss 3406.469970703125
epochs 196 loss 3430.6412353515625
epochs 197 loss 3461.6932983398438
epochs 198 loss 3507.2491455078125
epochs 199 loss 3615.1807861328125
epochs 200 loss 3419.0991821289062
epochs 201 loss 3500.8094482421875
epochs 202 loss 3563.2241821289062
epochs 203 loss 3580.5018310546875
epochs 204 loss 3232.864013671875
epochs 205 loss 3639.5174560546875
epochs 206 loss 3535.3421020507812
epochs 207 loss 3495.1929321289062
epochs 208 loss 3595.2003784179688
epochs 209 loss 3611.3313598632812
epochs 210 loss 3729.2713623046875
epochs 211 loss 3365.25927734375
epochs 212 loss 3216.0774536132812
epochs 213 loss 3613.0810546875
