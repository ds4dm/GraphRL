nohup: ignoring input
| Xavier Initialization
| Xavier Initialization
Supervised Validation started
heuristic: min_degree learning rate: 0.001 DataSet: ErgDataset

/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/gcn/models_gcn.py:85: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
steps 0 loss 0.004223014284402405 min_degree_performance 12716.78 gcn_performance 16193.215 random_performance 16200.82
steps 1000 loss 0.004523966399759013 min_degree_performance 12716.78 gcn_performance 16202.91 random_performance 16200.82
steps 2000 loss 0.004384777639384427 min_degree_performance 12716.78 gcn_performance 16190.955 random_performance 16200.82
steps 3000 loss 0.004307052712688908 min_degree_performance 12716.78 gcn_performance 16192.935 random_performance 16200.82
steps 4000 loss 0.004294741953287176 min_degree_performance 12716.78 gcn_performance 16210.375 random_performance 16200.82
steps 5000 loss 0.004272100075732311 min_degree_performance 12716.78 gcn_performance 16198.95 random_performance 16200.82
steps 6000 loss 0.00424990051327398 min_degree_performance 12716.78 gcn_performance 16213.025 random_performance 16200.82
steps 7000 loss 0.004321450597456716 min_degree_performance 12716.78 gcn_performance 16192.045 random_performance 16200.82
steps 8000 loss 0.004312700473973172 min_degree_performance 12716.78 gcn_performance 16205.275 random_performance 16200.82
steps 9000 loss 0.004330928933233768 min_degree_performance 12716.78 gcn_performance 16168.425 random_performance 16200.82
steps 10000 loss 0.004395604234168832 min_degree_performance 12716.78 gcn_performance 16205.435 random_performance 16200.82
steps 11000 loss 0.004422111487379575 min_degree_performance 12716.78 gcn_performance 16199.825 random_performance 16200.82
steps 12000 loss 0.004376421564281236 min_degree_performance 12716.78 gcn_performance 16191.515 random_performance 16200.82
steps 13000 loss 0.0008922682066059101 min_degree_performance 12716.78 gcn_performance 12903.82 random_performance 16200.82
steps 14000 loss 0.0008670247246492309 min_degree_performance 12716.78 gcn_performance 12838.0 random_performance 16200.82
steps 15000 loss 0.0008248623340678796 min_degree_performance 12716.78 gcn_performance 12856.135 random_performance 16200.82
steps 16000 loss 0.000804652879292195 min_degree_performance 12716.78 gcn_performance 12857.555 random_performance 16200.82
steps 17000 loss 0.0008696773737064346 min_degree_performance 12716.78 gcn_performance 12842.72 random_performance 16200.82
steps 18000 loss 0.0008244496362119274 min_degree_performance 12716.78 gcn_performance 12860.425 random_performance 16200.82
steps 19000 loss 0.0008517295659857437 min_degree_performance 12716.78 gcn_performance 12871.53 random_performance 16200.82
steps 20000 loss 0.0009054971088001286 min_degree_performance 12716.78 gcn_performance 12838.37 random_performance 16200.82
steps 21000 loss 0.0007735280692582883 min_degree_performance 12716.78 gcn_performance 12857.505 random_performance 16200.82
steps 22000 loss 0.0009292525223697093 min_degree_performance 12716.78 gcn_performance 12846.585 random_performance 16200.82
