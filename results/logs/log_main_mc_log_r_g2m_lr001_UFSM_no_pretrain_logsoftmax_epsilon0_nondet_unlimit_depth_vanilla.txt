nohup: ignoring input
[[1 2 3]
 [4 5 6]]
| Xavier Initialization
| Xavier Initialization
Use Critic:
False
/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/gcn/models_gcn.py:85: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.t())
epochs 0 loss -17.513620376586914
parameter name actor.gc1.weight parameter value tensor(1.00000e-02 *
       [[-1.5938]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor([ 0.], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor(1.00000e-02 *
       [[-1.3048]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor([ 0.], device='cuda:0')
epochs 2 loss -19.484187602996826
epochs 3 loss 1.457942008972168
epochs 4 loss -3.036365509033203
epochs 5 loss 6.209444999694824
epochs 6 loss -35.25120162963867
epochs 7 loss -1.890882968902588
epochs 8 loss -10.817886352539062
epochs 9 loss 18.986858367919922
epochs 10 loss -8.036669731140137
epochs 11 loss -34.36635875701904
epochs 12 loss -17.030122756958008
epochs 13 loss -13.973627090454102
epochs 14 loss 13.327513694763184
epochs 15 loss -34.37827777862549
epochs 16 loss -26.245551109313965
epochs 17 loss -19.937301635742188
epochs 18 loss -32.2077431678772
epochs 19 loss -33.78873348236084
epochs 20 loss -23.979651927947998
epochs 21 loss 10.008097171783447
epochs 22 loss -23.21757698059082
epochs 23 loss -42.07097148895264
epochs 24 loss -45.02583980560303
