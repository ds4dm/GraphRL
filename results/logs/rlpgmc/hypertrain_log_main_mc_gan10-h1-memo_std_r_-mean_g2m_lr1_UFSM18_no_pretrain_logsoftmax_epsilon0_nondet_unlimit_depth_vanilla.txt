nohup: ignoring input
[[1 2 3]
 [4 5 6]]
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
| Xavier Initialization
Supervised Training started
heuristic: min_degree actor learning rate: [0.1] epochs: 500 Train DataSet: UFSMDataset_Demo

Use Critic:
False
/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/gcn/models_gcn.py:382: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  features = F.log_softmax(features.view(-1))
parameter name actor.gc1.weight parameter value tensor(1.00000e-02 *
       [[-1.3048]], device='cuda:0')
parameter name actor.gc1.a parameter value tensor([[-0.9202],
        [ 0.5715]], device='cuda:0')
parameter name actor.gc1.bias parameter value tensor(1.00000e-03 *
       [[-1.3345]], device='cuda:0')
parameter name actor.gc2.weight parameter value tensor(1.00000e-02 *
       [[ 1.7918]], device='cuda:0')
parameter name actor.gc2.a parameter value tensor([[-1.4613],
        [-1.0421]], device='cuda:0')
parameter name actor.gc2.bias parameter value tensor(1.00000e-02 *
       [[-1.0210]], device='cuda:0')
parameter name actor.gc3.weight parameter value tensor(1.00000e-02 *
       [[-1.1191]], device='cuda:0')
parameter name actor.gc3.a parameter value tensor([[ 1.5293],
        [-0.8254]], device='cuda:0')
parameter name actor.gc3.bias parameter value tensor(1.00000e-02 *
       [[-1.1666]], device='cuda:0')
parameter name actor.gc4.weight parameter value tensor(1.00000e-02 *
       [[ 3.3369]], device='cuda:0')
parameter name actor.gc4.a parameter value tensor([[ 0.2253],
        [-1.5545]], device='cuda:0')
parameter name actor.gc4.bias parameter value tensor(1.00000e-02 *
       [[ 3.4472]], device='cuda:0')
parameter name actor.gc5.weight parameter value tensor(1.00000e-02 *
       [[ 2.0716]], device='cuda:0')
parameter name actor.gc5.a parameter value tensor([[-0.0987],
        [-0.5014]], device='cuda:0')
parameter name actor.gc5.bias parameter value tensor(1.00000e-02 *
       [[ 3.8838]], device='cuda:0')
parameter name actor.gc6.weight parameter value tensor(1.00000e-03 *
       [[ 8.7399]], device='cuda:0')
parameter name actor.gc6.a parameter value tensor([[-1.1768],
        [ 3.1645]], device='cuda:0')
parameter name actor.gc6.bias parameter value tensor(1.00000e-02 *
       [[-1.3004]], device='cuda:0')
parameter name actor.gc7.weight parameter value tensor(1.00000e-02 *
       [[-3.6877]], device='cuda:0')
parameter name actor.gc7.a parameter value tensor([[ 0.5360],
        [ 1.0465]], device='cuda:0')
parameter name actor.gc7.bias parameter value tensor(1.00000e-03 *
       [[-2.1041]], device='cuda:0')
parameter name actor.gc8.weight parameter value tensor(1.00000e-03 *
       [[-3.4467]], device='cuda:0')
parameter name actor.gc8.a parameter value tensor([[-2.1444],
        [ 0.9552]], device='cuda:0')
parameter name actor.gc8.bias parameter value tensor(1.00000e-02 *
       [[-1.8997]], device='cuda:0')
parameter name actor.gc9.weight parameter value tensor(1.00000e-03 *
       [[ 2.3846]], device='cuda:0')
parameter name actor.gc9.a parameter value tensor([[ 1.0463],
        [-1.1183]], device='cuda:0')
parameter name actor.gc9.bias parameter value tensor(1.00000e-03 *
       [[ 1.6820]], device='cuda:0')
parameter name actor.gc10.weight parameter value tensor(1.00000e-02 *
       [[ 2.3301]], device='cuda:0')
parameter name actor.gc10.a parameter value tensor([[-0.9387],
        [-0.2340]], device='cuda:0')
parameter name actor.gc10.bias parameter value tensor(1.00000e-02 *
       [[-3.4256]], device='cuda:0')
/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/rl/train_a2c_mc.py:542: RuntimeWarning: invalid value encountered in double_scalars
  _val_ave_gcn = np.sum(val_gcn_greedy) / len(val_gcn_greedy)
/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/rl/train_a2c_mc.py:548: RuntimeWarning: invalid value encountered in double_scalars
  _val_ave_mind = np.sum(val_mind) / len(val_mind)
epochs 0 loss -754.2942504882812 train min_degreeperformance 8959.0 train gcn performance 230354.0 val min_degreeperformance nan val gcn performance nan
epochs 1 loss -754.2978515625 train min_degreeperformance 8959.0 train gcn performance 242353.0 val min_degreeperformance nan val gcn performance nan
epochs 2 loss -863.2025146484375 train min_degreeperformance 8959.0 train gcn performance 251498.0 val min_degreeperformance nan val gcn performance nan
epochs 3 loss -712.8838500976562 train min_degreeperformance 8959.0 train gcn performance 248391.0 val min_degreeperformance nan val gcn performance nan
epochs 4 loss -707.4400634765625 train min_degreeperformance 8959.0 train gcn performance 226062.0 val min_degreeperformance nan val gcn performance nan
epochs 5 loss -741.1320190429688 train min_degreeperformance 8959.0 train gcn performance 334051.0 val min_degreeperformance nan val gcn performance nan
epochs 6 loss -777.2989501953125 train min_degreeperformance 8959.0 train gcn performance 222532.0 val min_degreeperformance nan val gcn performance nan
epochs 7 loss -838.3094482421875 train min_degreeperformance 8959.0 train gcn performance 232492.0 val min_degreeperformance nan val gcn performance nan
epochs 8 loss -848.310302734375 train min_degreeperformance 8959.0 train gcn performance 261890.0 val min_degreeperformance nan val gcn performance nan
epochs 9 loss -683.8272094726562 train min_degreeperformance 8959.0 train gcn performance 402714.0 val min_degreeperformance nan val gcn performance nan
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/THCThrustAllocator.cuh line=21 error=2 : out of memory
Traceback (most recent call last):
  File "main_mc.py", line 258, in <module>
    density = args.p
  File "/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/rl/train_a2c_mc.py", line 374, in train_and_validate
    action, log_prob, reward, value_current, value_next, x_model = self.model(x_model) # forward propagation,action: node selected, reward: nb edges added
  File "/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/rl/model_a2c.py", line 167, in forward
    probs = self.actor(features, adj_M)  # call actor to get a selection distribution
  File "/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/gcn/models_gcn.py", line 381, in forward
    features = self.gc10(features, adj_matrix)
  File "/home/x86_64-unknown-linux_ol7-gnu/anaconda-5.2.0/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_workspace/liudefen/PycharmProjects/PycharmProjects/GraphRL/gcn/layers_gcn.py", line 415, in forward
    features = torch.spmm(atten_sparse, features) + features_hat # adjacency matrix * features
RuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/THCThrustAllocator.cuh:21
